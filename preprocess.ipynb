{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import underthesea\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    pre = metrics.precision_score(y_true, y_pred, average='weighted')\n",
    "    re = metrics.recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'Accuracy': acc,\n",
    "        'Precision': pre,\n",
    "        'Recall': re,\n",
    "        \"F1-score\": f1,\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, label):\n",
    "    print()\n",
    "    print(\"Classification report\")\n",
    "    print(metrics.classification_report(y_true, y_pred, labels=label))\n",
    "    print()\n",
    "    conf = metrics.confusion_matrix(y_true=y_true, y_pred=y_pred, normalize='pred', labels=label)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(conf,annot=True,annot_kws={\"size\": 16}, fmt='.3f', xticklabels=label,yticklabels=label)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def train_test(pipe, X_train, X_test, y_train, y_test):\n",
    "    pipe.fit(list(X_train.values.ravel()), y_train.values.ravel())\n",
    "    pred = pipe.predict(list(X_test.values.ravel()))\n",
    "    result = evaluate(y_test.values.ravel(), pred)\n",
    "    result = pd.DataFrame([result], index=['value'])\n",
    "    print(result)\n",
    "    plot_confusion_matrix(y_test.values.ravel(), pred, label=pipe.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_captial_word(word:str):\n",
    "    return sum(1 for c in word if c.isupper())\n",
    "\n",
    "\n",
    "def check_invalid_desc(txt, max_num=2):\n",
    "    first_token = txt.split(\" \")[0]\n",
    "    num_capt = get_number_of_captial_word(first_token)\n",
    "    if (num_capt >= max_num):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_invalid_desc2(sent):\n",
    "    tokens = sent.split(' ')\n",
    "    if get_number_of_captial_word(tokens[0]) <= 3 and get_number_of_captial_word(tokens[1]) <= 2:\n",
    "        return False\n",
    "    elif tokens[1].islower():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def split_cap(txt):\n",
    "    first_token, second_token = txt.split(\" \")[:2]\n",
    "    if first_token.isupper() and second_token.islower():\n",
    "         return txt\n",
    "    for i in range(1,len(txt)):\n",
    "        # if txt[i-1].isupper() and (txt[i].islower() or (not txt[i].isalpha())):\n",
    "        if txt[i-1].isupper() and txt[i].islower():\n",
    "            txt =  \"\".join(txt[:i-1]) + ' ' + \"\".join(txt[i-1:])\n",
    "            return txt\n",
    "        elif txt[i-1].isupper() and txt[i].isnumeric():\n",
    "            txt =  \"\".join(txt[:i]) + ' ' + \"\".join(txt[i:])\n",
    "            return txt\n",
    "    return txt\n",
    "\n",
    "\n",
    "def processDescription(df, true_columns):\n",
    "    '''\n",
    "    Remove the case where comes from the crawling procedure.\n",
    "    Description column some texts have first words merge with the news description.\n",
    "    '''\n",
    "    final_dataset = []\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp['cap_first'] = tmp['Description'].apply(check_invalid_desc)\n",
    "\n",
    "    final_dataset.append(tmp[tmp['cap_first'] == False][true_columns])\n",
    "\n",
    "    tmp1 = tmp[tmp['cap_first'] == True].copy()\n",
    "    tmp1['cap_first'] = tmp1['Description'].apply(check_invalid_desc2)\n",
    "\n",
    "    good_tmp1_true = tmp1[tmp1['cap_first'] == False].copy()\n",
    "    good_tmp1_true['Description'] = good_tmp1_true['Description'].apply(split_cap)\n",
    "\n",
    "    final_dataset.append(good_tmp1_true[true_columns])\n",
    "\n",
    "    tmp2 = tmp1[tmp1['cap_first'] == True].copy()\n",
    "    tmp2['Description'] = tmp2['Description'].apply(split_cap)\n",
    "\n",
    "    final_dataset.append(tmp2[true_columns])\n",
    "\n",
    "    final_dataset = pd.concat(final_dataset, axis=0)\n",
    "    final_dataset['Description'] = final_dataset['Description'].apply(lambda x: x.strip())\n",
    "    return final_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(txt):\n",
    "    return underthesea.word_tokenize(txt, format='text')\n",
    "    # return ViTokenizer.tokenize(txt)\n",
    "\n",
    "\n",
    "def process_txt(txt, lower=True):\n",
    "    txt = unicodedata.normalize('NFKC', str(txt))\n",
    "    txt = re.sub(r'[^\\w\\s]', '', txt)\n",
    "    txt = re.sub(r'[\\d]', '', txt)\n",
    "    txt = re.sub('\\s+', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    if lower:\n",
    "        txt = txt.lower()\n",
    "    txt = tokenizer(txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARINING: For new data\n",
    "\n",
    "df_dtype = {'Category': 'category', 'Sub Category': 'category', 'Title': 'object', 'Description': 'object', 'Content': 'object'}\n",
    "df = pd.read_csv(\"./vnexpress_crawled.csv\", dtype=df_dtype)\n",
    "true_columns = list(df.columns)\n",
    "print(f\"Dataframe shape: {df.shape}\")\n",
    "\n",
    "df = processDescription(df, true_columns)\n",
    "df['Title'] = df['Title'].parallel_apply(process_txt)\n",
    "df['Description'] = df['Description'].parallel_apply(process_txt)\n",
    "df['Content'] = df['Content'].parallel_apply(process_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('processed.csv', index=False)\n",
    "df.to_feather('processed.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
