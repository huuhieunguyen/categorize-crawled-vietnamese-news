{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from utils import train_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('processed.feather')\n",
    "print(f\"Data frame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = [k for k, v in df['Category'].value_counts().items() if v < 500]\n",
    "df = df.dropna()\n",
    "data = df[~df['Category'].isin(exclude_cols)].copy()\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_df['Category'] = le.fit_transform(train_df['Category'])\n",
    "test_df['Category'] = le.transform(test_df['Category'])\n",
    "\n",
    "print(f\"train_df shape: {train_df.shape}\")\n",
    "print(f\"train_df shape: {test_df.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoBERT():\n",
    "    phobert = None\n",
    "    tokenizer = None\n",
    "\n",
    "    def loadModel():\n",
    "        if __class__.phobert is None or __class__.tokenizer is None:\n",
    "            __class__.phobert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "            __class__.tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "        return __class__.phobert, __class__.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, df, col):\n",
    "        self.phobert, self.tokenizer = PhoBERT.loadModel()\n",
    "        self.df = df[[col, 'Category']]\n",
    "        self.device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "        self.phobert = self.phobert.to(self.device)\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence, label = self.df.iloc[index, :].values\n",
    "        token_ids = self.tokenizer.encode(sentence, padding=True, truncation=True, max_length=256, return_tensors='pt').to(self.device)\n",
    "        with torch.no_grad():\n",
    "            features = self.phobert(token_ids)['pooler_output']\n",
    "        return features.squeeze(0), torch.tensor(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = 'Title'\n",
    "\n",
    "train_data = NewsDataset(df=train_df,col=feature_col)\n",
    "train_loader = DataLoader(train_data, batch_size=64)\n",
    "\n",
    "test_data = NewsDataset(df=test_df,col=feature_col)\n",
    "test_loader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "train_features_lst = []\n",
    "train_label_lst = []\n",
    "\n",
    "for sent, label in tqdm(train_loader, desc=\"Create training data\"):\n",
    "    sentence = sent.detach().cpu().numpy() \n",
    "    label_idx = label.numpy()\n",
    "    train_features_lst.append(sentence)\n",
    "    train_label_lst.append(label_idx)\n",
    "\n",
    "train_features = np.concatenate(train_features_lst)\n",
    "train_labels = np.concatenate(train_label_lst)\n",
    "\n",
    "print(train_features.shape, train_labels.shape)\n",
    "\n",
    "test_features_lst = []\n",
    "test_label_lst = []\n",
    "\n",
    "for sent, label in tqdm(test_loader, desc=\"Create testing data\"):\n",
    "    sentence = sent.detach().cpu().numpy() \n",
    "    label_idx = label.numpy()\n",
    "    test_features_lst.append(sentence)\n",
    "    test_label_lst.append(label_idx)\n",
    "\n",
    "test_features = np.concatenate(test_features_lst)\n",
    "test_labels = np.concatenate(test_label_lst)\n",
    "\n",
    "print(test_features.shape, test_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(max_iter=5000)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "scores = cross_validate(model, train_features, train_labels, cv=kfold, scoring=['f1_weighted', 'precision_weighted', 'recall_weighted', 'accuracy'], n_jobs=-1, verbose=2)\n",
    "scores_df = pd.DataFrame(scores).T\n",
    "scores_df['mean'] = scores_df.mean(axis=1)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "scores = cross_validate(model, train_features, train_labels, cv=kfold, scoring=['f1_weighted', 'precision_weighted', 'recall_weighted', 'accuracy'], n_jobs=-1, verbose=2)\n",
    "scores_df = pd.DataFrame(scores).T\n",
    "scores_df['mean'] = scores_df.mean(axis=1)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "scores = cross_validate(model, train_features, train_labels, cv=kfold, scoring=['f1_weighted', 'precision_weighted', 'recall_weighted', 'accuracy'], n_jobs=-1, verbose=2)\n",
    "scores_df = pd.DataFrame(scores).T\n",
    "scores_df['mean'] = scores_df.mean(axis=1)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "scores = cross_validate(model, train_features, train_labels, cv=kfold, scoring=['f1_weighted', 'precision_weighted', 'recall_weighted', 'accuracy'], n_jobs=-1, verbose=2)\n",
    "scores_df = pd.DataFrame(scores).T\n",
    "scores_df['mean'] = scores_df.mean(axis=1)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "scores = cross_validate(model, train_features, train_labels, cv=kfold, scoring=['f1_weighted', 'precision_weighted', 'recall_weighted', 'accuracy'], n_jobs=-1, verbose=2)\n",
    "scores_df = pd.DataFrame(scores).T\n",
    "scores_df['mean'] = scores_df.mean(axis=1)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(probability=True)\n",
    "train_test(model, train_features, test_features, train_labels, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
